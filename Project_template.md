# Задание 1. Исследование моделей и инфраструктуры

## 1. Сравнение LLM-моделей

Параметр | Локальные модели | Облачные модели|
-|-|-
Качество ответов|Высокое, но зависит от настройки и данных; возможность fine-tuning|Очень высокое; оптимизированы для многих сценариев использования 
Скорость работы |Может требовать больше ресурсов, чем облачные решения, особенно для больших моделей|Быстрая обработка благодаря высокопроизводительным серверам
Стоимость владения|Необходимы инвестиции в инфраструктуру, лицензирование|Плата за использование, зависит от объема запросов, но без дополнительных затрат на инфраструктуру
Удобство развёртывания|Требует настройки серверов, сложнее в управлении|Меньше усилий для развёртывания, простота интеграции с существующими системами

## 2. Сравнение моделей эмбеддингов

Качество поиска и стоимость владения имеют такие же аргументы из сравнения выше

Параметр | Локальные модели | Облачные модели|
-|-|-
Скорость создания индекса | Может быть медленнее, требуется больше вычислительных ресурсов | Быстрая генерация, так как облачные платформы обычно мощнее

## 3. Сравнение векторных баз ChromaDB и FAISS:

chromadb - это простой вариант для начала использования векторных БД. Реализована на Python. Она "дружелюбна" к пользователю и имеет достаточно высокую **скорость поиска и индексации** в отношении затрачиваемого **времени на внедрение**.

faiss - векторная БД, которая реализована на C++. Она **требует обучения** для настройки и интеграции, так как не имеет встроенных механизмов фильтрации и хранения метаданных. Это необходимо будет реализовывать вручную, но взамен она дает огромную **скорость поиска и индексации** с меньшим потреблением памяти.


**Стоимость владения** напрямую зависит от потребностей проекта, так как обе БД являются open-source решениями. Стоимость будет определяться исходя из масштаба инфраструктуры.

## 4. Минимальная конфигурация сервера

| LLM      | Embeddings | RAM, Гб | GPU, Гб | CPU, ядер |
| --- | --- | --- | --- | --- |
| локально | облако   | 64 | 24 | 12 |
| облако   | локально | 32 | 14 | 12 |
| облако   | облако   | 8 | опционально| 8 |
| локально | локально | unlimited | unlimited | unlimited |

## Итого

Локальные варианты предпочтительнее, так как во внутренних документах содержится чувствительная информация.
Для итогового решения возьмем локальную эмбеддинг-модель [all‑MiniLM‑L6‑v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2), ChromaDB из-за низкого порога входа и [Qwen/Qwen3-0.6B](https://huggingface.co/Qwen/Qwen3-0.6B) в качестве локального варианта miniLLM из-за ограниченности ресурсов.

# Задание 2. Подготовка базы знаний

- Предметная область: The Big Bang Theory
- Информация берется из с bigbangtheory.fandom.com
- Так как объем документов было большой, то брался раздел биографии о главных персонажах вселенной.
- Всего 7 документов.

В документах были заменены имена персонажей на рандомные значения. Каждое имя было разбито на слова и заменены независимо. Словарь замен доступен [тут](./terms_map.json)

Скрипт с получением и преобразованием доступен [тут](./collector.py). Использовался Python 3.9.13


